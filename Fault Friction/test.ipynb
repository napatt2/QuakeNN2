{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Vector Wave Simulation using PINNs\n",
    "\n",
    "This notebook demonstrates a forward simulation of vector waves using a Physics-Informed Neural Network (PINN) framework. In this notebook, we:\n",
    "\n",
    "- Present the governing equations and explain each variable and dataset column.\n",
    "- Describe the data processing steps.\n",
    "- Define and train a neural network to solve the PDE system.\n",
    "- Predict and visualize the solution.\n",
    "\n",
    "---\n",
    "\n",
    "#### Governing Equations\n",
    "\n",
    "We aim to solve the following system (in nondimensional form):\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\frac{d\\tilde{u}}{dt} &= \\tilde{v}, \\\\\n",
    "\\frac{d\\tilde{v}}{dt} &= \\kappa(v_0 t - \\tilde{u}) - \\alpha\\Big(f_0 + a \\ln(\\tilde{v}) + b \\ln(\\tilde{\\theta})\\Big), \\\\\n",
    "\\frac{d\\tilde{\\theta}}{dt} &= -\\tilde{v}\\tilde{\\theta}\\ln(\\tilde{v}\\tilde{\\theta}).\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "The network is trained to predict the solutions for:\n",
    "\n",
    "- \\(\\tilde{u}\\): Slip\n",
    "- \\(\\tilde{v}\\): Slip rate\n",
    "- \\(\\tilde{\\theta}\\): State variable\n",
    "\n",
    "---\n",
    "\n",
    "#### Explanation of Variables and Dataset Columns\n",
    "\n",
    "- **Dataset Columns:**\n",
    "  - **`Var1`**: Time\n",
    "  - **`y1_1`**: \\(\\tilde{u}\\) (slip)\n",
    "  - **`y1_2`**: \\(\\tilde{v}\\) (slip rate)\n",
    "  - **`y1_3`**: \\(\\tilde{\\theta}\\) (state variable)\n",
    "\n",
    "- **Model Parameters:**\n",
    "  - \\(\\alpha = 9.81\\)\n",
    "  - \\(\\kappa = 0.25\\)\n",
    "  - \\(v_0 = 1\\)\n",
    "  - \\(f_0 = 0.2\\)\n",
    "  - \\(a = 0.2\\)\n",
    "  - \\(b = 0.3\\)\n",
    "\n",
    "- **Neural Network Architecture:**\n",
    "  - **Input:** Time \\(t\\) (1 neuron)\n",
    "  - **Hidden layers:** 6 layers with 64 neurons each (using the Tanh activation function)\n",
    "  - **Output:** 3 neurons corresponding to \\(\\tilde{u}\\), \\(\\tilde{v}\\), and \\(\\tilde{\\theta}\\)\n",
    "\n",
    "- **Training Data:**\n",
    "  - 20,000 residual (collocation) points in the time domain \\([0, 100]\\).\n",
    "  - Measurement (boundary/initial) data is obtained by interpolating the first 10,000 data points to 25 equidistant points.\n",
    "\n",
    "---\n",
    "\n",
    "#### Training Process Overview\n",
    "\n",
    "1. **Data Import and Preprocessing:** Load the CSV dataset, select the first 10,000 data points, and interpolate to obtain 25 measurement points.\n",
    "2. **Define Boundary Conditions:** Use the interpolated data for each variable to create boundary conditions.\n",
    "3. **Define the PDE System:** Implement the governing equations using DeepXDE’s automatic differentiation.\n",
    "4. **Neural Network Setup:** Create a feed-forward network and apply an output transform to enforce the initial conditions.\n",
    "5. **Model Compilation and Training:** Compile the model using the Adam optimizer and train for 50,000 iterations.\n",
    "6. **Prediction and Visualization:** Predict the solution over the time domain and compare it with the true data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepxde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepxde as dde\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from deepxde.backend import tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Processing\n",
    "\n",
    "The dataset is assumed to be stored in a CSV file (e.g., `../Dataset/Forward_vector_wave.csv`) with the following columns:\n",
    "\n",
    "- **`Var1`**: Time\n",
    "- **`y1_1`**: \\(\\tilde{u}\\) (slip)\n",
    "- **`y1_2`**: \\(\\tilde{v}\\) (slip rate)\n",
    "- **`y1_3`**: \\(\\tilde{\\theta}\\) (state variable)\n",
    "\n",
    "We extract the first 10,000 data points and interpolate these to obtain 25 equidistant measurement points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('../Dataset/Forward_vector_wave.csv')  # Adjust the file path as needed\n",
    "raw = raw.iloc[0:10000]\n",
    "\n",
    "# Extract columns\n",
    "observe_t = raw['Var1']\n",
    "u_ext = raw['y1_1']\n",
    "v_ext = raw['y1_2']\n",
    "theta_ext = raw['y1_3']\n",
    "\n",
    "# Interpolate to get 25 equidistant measurement points\n",
    "t_int = np.linspace(0, 100, 25)\n",
    "u_int = np.interp(t_int, observe_t.values, u_ext.values)\n",
    "v_int = np.interp(t_int, observe_t.values, v_ext.values)\n",
    "theta_int = np.interp(t_int, observe_t.values, theta_ext.values)\n",
    "\n",
    "# Plot the true data and measurement points\n",
    "plt.figure()\n",
    "plt.plot(observe_t, u_ext, label=\"u\")\n",
    "plt.plot(observe_t, v_ext, label=\"v\")\n",
    "plt.plot(observe_t, theta_ext, label=\"θ\")\n",
    "plt.scatter(t_int, u_int, color=\"red\", label=\"Measured u\")\n",
    "plt.scatter(t_int, v_int, color=\"green\", label=\"Measured v\")\n",
    "plt.scatter(t_int, theta_int, color=\"blue\", label=\"Measured θ\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Boundary/Initial Conditions\n",
    "\n",
    "We now create boundary conditions for each variable using the measured (interpolated) data. These conditions will help guide the network to satisfy the initial and measurement constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_int = t_int.reshape((-1, 1))\n",
    "u_int = nu_int.reshape((-1, 1))\n",
    "v_int = v_int.reshape((-1, 1))\n",
    "theta_int = theta_int.reshape((-1, 1))\n",
    "\n",
    "observe_y0 = dde.icbc.PointSetBC(t_int, nu_int, component=0)\n",
    "observe_y1 = dde.icbc.PointSetBC(t_int, v_int, component=1)\n",
    "observe_y2 = dde.icbc.PointSetBC(t_int, theta_int, component=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the PDE/ODE System\n",
    "\n",
    "We define the system of equations using DeepXDE’s automatic differentiation. To avoid issues with taking the logarithm of zero, we use `tf.clip_by_value` to restrict the domain of \\(\\tilde{v}\\) and \\(\\tilde{\\theta}\\).\n",
    "\n",
    "The equations implemented are:\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\frac{d\\tilde{u}}{dt} &= \\tilde{v}, \\\\\n",
    "\\frac{d\\tilde{v}}{dt} &= \\kappa(v_0 t - \\tilde{u}) - \\alpha\\Big(f_0 + a \\ln(\\tilde{v}) + b \\ln(\\tilde{\\theta})\\Big), \\\\\n",
    "\\frac{d\\tilde{\\theta}}{dt} &= -\\tilde{v}\\tilde{\\theta}\\ln(\\tilde{v}\\tilde{\\theta}).\n",
    "\\end{aligned}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 9.81\n",
    "kappa = 0.25\n",
    "v0 = 1\n",
    "f0 = 0.2\n",
    "a = 0.2\n",
    "b = 0.3\n",
    "\n",
    "def ode_system(x, y):\n",
    "    # Extract variables from the network output\n",
    "    u = y[:, 0:1]\n",
    "    v = y[:, 1:2]\n",
    "    theta = y[:, 2:3]\n",
    "\n",
    "    # Compute time derivatives using automatic differentiation\n",
    "    du_t = dde.grad.jacobian(y, x, i=0)\n",
    "    dv_t = dde.grad.jacobian(y, x, i=1)\n",
    "    dtheta_t = dde.grad.jacobian(y, x, i=2)\n",
    "\n",
    "    # Define the system of ODEs\n",
    "    eq1 = du_t - tf.clip_by_value(v, 0, 13)\n",
    "    eq2 = dv_t - kappa * (v0 * x - u) + alpha * (f0 + a * tf.math.log(tf.clip_by_value(v, 0, 13)) + b * tf.math.log(tf.clip_by_value(theta, 0, 11)))\n",
    "    eq3 = dtheta_t + (tf.clip_by_value(v, 0, 13) * tf.clip_by_value(theta, 0, 11) * tf.math.log(tf.clip_by_value(v, 0, 13) * tf.clip_by_value(theta, 0, 11)))\n",
    "    \n",
    "    return [eq1, eq2, eq3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Geometry and Generate Residual Points\n",
    "\n",
    "We define the time domain \\([0, 100]\\) as our geometry. Next, we generate 20,000 collocation (residual) points to evaluate the PDE residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = dde.geometry.TimeDomain(0, 100)\n",
    "\n",
    "# Create the data object for the PDE problem\n",
    "# The list [observe_y0, observe_y1, observe_y2] specifies the measurement conditions\n",
    "data = dde.data.PDE(geom, ode_system, [observe_y0, observe_y1, observe_y2], 20000, 0, num_test=3000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Setup\n",
    "\n",
    "We construct a feed-forward neural network with the following architecture:\n",
    "\n",
    "- **Input:** 1 neuron (time) \n",
    "- **Hidden Layers:** 6 layers with 64 neurons each (using Tanh activation)\n",
    "- **Output:** 3 neurons corresponding to \\(\\tilde{u}\\), \\(\\tilde{v}\\), and \\(\\tilde{\\theta}\\)\n",
    "\n",
    "An output transform is applied to help enforce the initial conditions (e.g., setting \\(\\tilde{u}(0)=1\\), \\(\\tilde{v}(0)=0.5\\), \\(\\tilde{\\theta}(0)=1\\))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = [1] + [64] * 6 + [3]\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot normal\"\n",
    "net = dde.nn.FNN(layer_size, activation, initializer)\n",
    "\n",
    "def output_transform(t, y):\n",
    "    # Transform the network output to help enforce the initial conditions\n",
    "    y1 = y[:, 0:1]\n",
    "    y2 = y[:, 1:2]\n",
    "    y3 = y[:, 2:3]\n",
    "    return tf.concat([y1 * tf.tanh(t) + 1, y2 * tf.tanh(t) + 0.5, y3 * tf.tanh(t) + 1], axis=1)\n",
    "\n",
    "net.apply_output_transform(output_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compilation and Training\n",
    "\n",
    "We compile the model using the Adam optimizer (learning rate = 0.0001) with equal loss weights. The model is then trained for 50,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=0.0001, loss_weights=[1, 1, 1, 1, 1, 1])\n",
    "\n",
    "losshistory, train_state = model.train(epochs=50000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Visualization\n",
    "\n",
    "We now predict the solution over the time domain \\([0, 100]\\) on a fine grid and compare the predictions with the true data. The true curves (from the dataset) are shown as solid lines, and the predicted curves are shown as dashed lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "# Plot true measurements (interpolated)\n",
    "plt.plot(observe_t, u_ext, color=\"black\", label=\"True u\")\n",
    "plt.plot(observe_t, v_ext, color=\"blue\", label=\"True v\")\n",
    "plt.plot(observe_t, theta_ext, color=\"brown\", label=r'True $\\theta$')\n",
    "\n",
    "# Predict on a finer grid\n",
    "t = np.linspace(0, 100, 10000).reshape(-1, 1)\n",
    "sol_pred = model.predict(t)\n",
    "\n",
    "u_pred = sol_pred[:, 0:1]\n",
    "v_pred = sol_pred[:, 1:2]\n",
    "theta_pred = sol_pred[:, 2:3]\n",
    "\n",
    "plt.plot(t, u_pred, color=\"red\", linestyle=\"dashed\", label=\"Predicted u\")\n",
    "plt.plot(t, v_pred, color=\"orange\", linestyle=\"dashed\", label=\"Predicted v\")\n",
    "plt.plot(t, theta_pred, color=\"green\", linestyle=\"dashed\", label=r\"Predicted $\\theta$\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook, we implemented a PINN to simulate forward vector wave propagation by solving a system of differential equations. We explained the governing equations and variables (including dataset columns), described the neural network architecture and training process, and compared the predicted solution with the true data.\n",
    "\n",
    "Feel free to modify the equations, parameters, and network architecture as needed for your application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
